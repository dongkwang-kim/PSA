from __future__ import annotations


import json
from pathlib import Path
from typing import List, Tuple, Dict, Any
from dotenv import load_dotenv
import requests
import base64
import time
import os
from PIL import Image


import numpy np
import faiss
import bm25s
from datasets import load_dataset
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from sentence_transformers import SentenceTransformer
from Stemmer import Stemmer
from tqdm import tqdm
import warnings
import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"
warnings.filterwarnings('ignore')
from datasets import load_dataset
from collections import defaultdict

load_dotenv()

MODEL_NAME = "gpt-4.1-mini"
TEMPERATURE = 0.2
# INDEX_DIR = Path("toys_bm25s_index")
INDEX_DIR = Path("toys_bm25s_index")
VEC_DIR = Path("toys_faiss")
TOP_KS = [20, 20, 20, 4]        # pool sizes per round
MAX_PRODUCTS = None                # None â†’ full split; set small for demo
SEM_K_FACTOR = 2                  # retrieve k*factor from each modality
HYBRID_WEIGHT = 0.5               # 0.5 lexical + 0.5 semantic
EMBED_MODEL_NAME = "BAAI/bge-small-en-v1.5"
EMBED_DIM = 384
NOVITA_API_URL = "https://api.novita.ai/v3/async/img2video"
NOVITA_API_KEY = os.getenv("NOVITA_API_KEY", "")  # .env íŒŒì¼ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°

# ì´ë¯¸ì§€-ë¹„ë””ì˜¤ ë³€í™˜ ëª¨ë¸ ì´ë¦„ ë° ê°€ê²© ì •ë³´
MODEL_NAMES = {
    "svd": "SVD",
    "svd_xt": "SVD-XT"
}

MODEL_PRICING = {
    "svd": 0.0134,
    "svd_xt": 0.024,
}

# ì´ë¯¸ì§€ ìµœëŒ€ í•´ìƒë„ ì„¤ì •
MAX_IMAGE_WIDTH = 576
MAX_IMAGE_HEIGHT = 1024


def _iter_products(limit: int | None = None):
    # 1) ë©”íƒ€ ì •ë³´
    meta_ds = load_dataset(
        "McAuley-Lab/Amazon-Reviews-2023",
        "raw_meta_Toys_and_Games",
        split="full",
        trust_remote_code=True,
    )

    # 2) ë¦¬ë·° ì •ë³´ â†’  parent_asin âœ [review strings]
    review_ds = load_dataset(
        "McAuley-Lab/Amazon-Reviews-2023",
        "raw_review_Toys_and_Games",
        split="full",
        trust_remote_code=True,
    )

    reviews_by_pid: dict[str, list[str]] = defaultdict(list)
    for row in review_ds:
        pid = row["parent_asin"]
        rv_title = row.get("title") or ""
        rv_text  = row.get("text")  or ""
        if rv_title or rv_text:
            reviews_by_pid[pid].append(f"{rv_title} {rv_text}".strip())

    # 3) ë©”íƒ€ + ë¦¬ë·°ë¥¼ í•©ì³ì„œ ë°˜í™˜
    for i, row in enumerate(meta_ds):
        if limit and i >= limit:
            break

        pid      = row["parent_asin"]
        title    = row.get("title") or ""
        features = " ".join(row.get("features", [])) if row.get("features") else ""
        desc     = row.get("description") or ""
        rv_blob  = " ".join(reviews_by_pid.get(pid, []))

        text = " ".join(filter(None, [str(title), str(features), str(desc), str(rv_blob)]))
        if text:
            yield {"id": pid, "text": text}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Index build / load
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_or_load_bm25_index(limit: int | None = None):
    """Load cached BM25s index or build it if absent."""
    stemmer = Stemmer("english")
    tokenizer = bm25s.tokenization.Tokenizer(stemmer=stemmer, stopwords='en')
    if INDEX_DIR.exists():
        print("[+] Loading cached BM25s indexâ€¦")
        retriever = bm25s.BM25.load(INDEX_DIR, mmap=True, load_corpus=True)
        tokenizer.load_vocab(INDEX_DIR)
        tokenizer.load_stopwords(INDEX_DIR)
        return retriever.corpus, tokenizer, retriever

    print("[+] Building BM25s index (first run â€” please wait)â€¦")
    corpus = list(_iter_products(limit))
    texts = [d["text"] for d in corpus]

    tokens = tokenizer.tokenize(texts)
    retriever = bm25s.BM25(corpus=corpus, backend="numba")
    retriever.index(tokens)
    retriever.vocab_dict = {str(k): v for k, v in retriever.vocab_dict.items()}

    INDEX_DIR.mkdir(parents=True, exist_ok=True)
    retriever.save(INDEX_DIR, corpus=corpus)
    tokenizer.save_vocab(INDEX_DIR)
    tokenizer.save_stopwords(INDEX_DIR)
    print(f"[âœ“] Saved index ({len(corpus):,} docs) â†’ {INDEX_DIR}")
    return corpus, tokenizer, retriever


def _build_or_load_vector_index(corpus: List[Dict[str, str]]):
    """Load or build FAISS index with BGE embeddings."""
    if (VEC_DIR / "index.faiss").exists():
        print("[+] Loading cached FAISS vector indexâ€¦")
        index = faiss.read_index(str(VEC_DIR / "index.faiss"))
        id_map = json.loads((VEC_DIR / "id_map.json").read_text())
        model = SentenceTransformer(EMBED_MODEL_NAME)
        return index, id_map, model

    print("[+] Building FAISS vector index (first run â€” please wait)â€¦")
    model = SentenceTransformer(EMBED_MODEL_NAME)
    model.max_seq_length = 512
    texts = [d["text"] for d in corpus]

    # Embed in batches to avoid OOM
    embeddings = []
    for i in tqdm(range(0, len(texts), 256), desc="Embedding"):
        batch_emb = model.encode(texts[i:i+256], show_progress_bar=False, normalize_embeddings=True)
        embeddings.append(batch_emb)
    embeddings = np.vstack(embeddings).astype('float32')

    # Build FAISS index (inner product on unit vectors == cosine sim)
    index = faiss.IndexFlatIP(EMBED_DIM)
    index.add(embeddings)

    # Persist
    VEC_DIR.mkdir(parents=True, exist_ok=True)
    faiss.write_index(index, str(VEC_DIR / "index.faiss"))
    (VEC_DIR / "id_map.json").write_text(json.dumps([d["id"] for d in corpus]))
    print(f"[âœ“] Saved FAISS index ({len(corpus):,} vectors) â†’ {VEC_DIR}")
    return index, [d["id"] for d in corpus], model

def bm25_search(query: str, idx_tuple, k: int) -> List[Tuple[str, str, float]]:
    _, tok, ret = idx_tuple
    q_tokens = tok.tokenize([query], update_vocab=False)
    docs_mat, scores_mat = ret.retrieve(q_tokens, k=k)
    docs, scores = docs_mat[0], scores_mat[0]
    return [(d["id"], d["text"], float(s)) for d, s in zip(docs, scores)]


def semantic_search(query: str, vec_tuple, k: int) -> List[Tuple[str, float]]:
    index, id_map, model = vec_tuple
    q_emb = model.encode([query], normalize_embeddings=True)[0].astype('float32')
    scores, idxs = index.search(q_emb[None, :], k)
    return [(id_map[int(i)], float(s)) for i, s in zip(idxs[0], scores[0])]


def hybrid_search(query: str, idx_tuple, vec_tuple, k: int, w: float = HYBRID_WEIGHT):
    # Retrieve from each modality
    bm25_hits = bm25_search(query, idx_tuple, k=k*SEM_K_FACTOR)
    sem_hits = semantic_search(query, vec_tuple, k=k*SEM_K_FACTOR)

    # Build score dicts
    bm25_dict = {pid: s for pid, _, s in bm25_hits}
    sem_dict = {pid: s for pid, s in sem_hits}

    # Normalise scores [0,1] within each modality
    if bm25_dict:
        bm_min, bm_max = min(bm25_dict.values()), max(bm25_dict.values())
    else:
        bm_min = bm_max = 0
    if sem_dict:
        sm_min, sm_max = min(sem_dict.values()), max(sem_dict.values())
    else:
        sm_min = sm_max = 0

    def norm(val, vmin, vmax):
        return 0.0 if vmax == vmin else (val - vmin) / (vmax - vmin)

    # Union of document ids
    docs_all = set(bm25_dict) | set(sem_dict)

    # Compute hybrid score
    scored_docs = []
    for pid in docs_all:
        bm = norm(bm25_dict.get(pid, bm_min), bm_min, bm_max)
        sm = norm(sem_dict.get(pid, sm_min), sm_min, sm_max)
        hybrid = w * bm + (1 - w) * sm
        scored_docs.append((pid, hybrid))

    # Sort by hybrid score desc
    scored_docs.sort(key=lambda x: x[1], reverse=True)

    # Retrieve full text for topâ€‘k
    corpus, _, _ = idx_tuple
    id_to_text = {d["id"]: d["text"] for d in corpus}
    topk = [(
        pid,
        id_to_text.get(pid, ""),
        score,
    ) for pid, score in scored_docs[:k]]
    return topk


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â¶ ì´ˆê¸° ì§ˆë¬¸ â€‘> ê²€ìƒ‰ìš© ì¿¼ë¦¬ë¡œ â€˜ì¬ì‘ì„±â€™
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REWRITE_PROMPT = PromptTemplate(
    input_variables=["user_input"],
    template=(
        "You are an expert eâ€‘commerce search assistant.\n\n"
        "Rewrite the user's input as a short, precise search query.\n"
        "If the input is already an optimal search query, return it unchanged.\n\n"
        "User: {user_input}\n"
        "Searchâ€‘query:"
    )
)
def rewrite_query(llm: ChatOpenAI, user_input: str) -> str:
    return llm.invoke(REWRITE_PROMPT.format(user_input=user_input)).content.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â· ëŒ€í™” ì´ë ¥ + ìƒˆ ë‹µë³€ -> â€˜ì¬êµ¬ì„±ëœ ì¿¼ë¦¬â€™ ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REFORM_PROMPT = PromptTemplate(
    input_variables=["history"],
    template=(
        "You are refining a productâ€‘search query.\n\n"
        "Conversation so far:\n{history}\n\n"
        "Compose ONE refined search query that captures all constraints implicit "
        "or explicit in the conversation. Return ONLY the query."
    )
)
def reformulate_query(llm: ChatOpenAI, turns: list[tuple[str, str]]) -> str:
    """turns = [(question, answer), ...]"""
    history_txt = "\n".join(f"Q: {q}\nA: {a}" for q, a in turns)
    return llm.invoke(REFORM_PROMPT.format(history=history_txt)).content.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â¸ ë§ˆì§€ë§‰ iteration: ë¬¸ì„œ 4ê°œ ìš”ì•½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SUMMARY_PROMPT = PromptTemplate(
    input_variables=["docs"],
    template=(
        "Summarise the following 4 product descriptions in bullet points (â‰¤â€¯40â€¯wordsâ€¯each).\n\n"
        "{docs}\n\n"
        "Return exactly 4 bullet points."
    )
)
def summarise_docs(llm: ChatOpenAI, docs: list[tuple[str, str]]) -> str:
    flat = "\n\n".join(f"[{pid}]\n{text}" for pid, text in docs)
    return llm.invoke(SUMMARY_PROMPT.format(docs=flat)).content.strip()


QUESTION_PROMPT = PromptTemplate(
    input_variables=["items", "context"],
    template=(
        # ì—­í• 
        "You are a helpful productâ€‘search assistant.\n\n"
        # ì»¨í…ìŠ¤íŠ¸ ì„¤ëª…
        "The products listed below were retrieved after considering the entire prior conversation with the user.\n\n"
        # ìƒí’ˆ ëª©ë¡
        "Products (id Â· snippet):\n{items}\n\n"
        # ëŒ€í™” ë§¥ë½
        "Conversation context:\n{context}\n\n"
        # ìš”ì²­
        "Using BOTH the conversation context and the product list, ask **one** concise followâ€‘up question "
        "that will help the user further specify what they want.\n"
        "â€¢ Do **not** recommend any specific item.\n"
        "â€¢ Return **only** the question text.\n"
        "â€¢ Do **not** ask something already answered or obvious from the context.\n\n"
    ),
)

def ask_disambiguation(llm: ChatOpenAI, docs, qa_turns):
    # build product snippets
    snippets = []
    for pid, text, _ in docs:
        # head = " ".join(text.split()[:20]) + (" â€¦" if len(text.split()) > 20 else "")
        head = text
        snippets.append(f"{pid} Â· {head}")

    context =  "None so far." if not qa_turns else "\n".join(f"Q: {turn[0]} A: {turn[1]}" for turn in qa_turns)
    # history = "None so far." if not prev_qs else "\n".join(f"- {q}" for q in prev_qs)
    prompt = QUESTION_PROMPT.format(items="\n".join(snippets), context=context)
    return llm.invoke(prompt).content.strip()


#### main loop



def conversational_search():
    # ãŠ€ ì¸ë±ìŠ¤ / LLM ì´ˆê¸°í™”
    bm25_idx = _build_or_load_bm25_index(MAX_PRODUCTS)
    vec_idx  = _build_or_load_vector_index(bm25_idx[0])
    llm      = ChatOpenAI(model_name=MODEL_NAME,
                          temperature=TEMPERATURE,
                          streaming=True)

    print("=== Hybrid Conversational Productâ€‘Search ===")
    raw_input = input("You: ").strip()
    if not raw_input or raw_input == "/exit":
        return

    # ãŠ Generationâ€‘1: ì´ˆê¸° ì¿¼ë¦¬ ì¬ì‘ì„±
    search_query = rewrite_query(llm, raw_input)
    print(f"[ rewrittenâ€‘query ] â†’ {search_query}")

    # ëŒ€í™” ì´ë ¥
    qa_turns: list[tuple[str, str]] = []
    # prev_questions: list[str] = []

    # ãŠ‚â€‘ãŠ‡ ë°˜ë³µ
    for round_idx, k in enumerate(TOP_KS, start=1):

        # Retrieval
        docs_k = hybrid_search(search_query, bm25_idx, vec_idx, k)
        # Generation: Clarifying question
        question = ask_disambiguation(llm, docs_k, qa_turns)
        # prev_questions.append(question)

        if question == "[END]" or round_idx == len(TOP_KS):
            #   â†³ ë§ˆì§€ë§‰ iteration: ë¬¸ì„œ 4ê°œ ìš”ì•½ í›„ ì¢…ë£Œ
            final_hits = hybrid_search(search_query, bm25_idx, vec_idx, 4)


            pids = [pid for pid, _, _ in final_hits]   # keep order if you like
            images_by_pid = fetch_images_for_pids(pids)

            summary = summarise_docs(llm, [(pid, txt) for pid, txt, _ in final_hits])
            print("\nğŸ”  Topâ€‘4 summary\n" + summary)

            print("\nğŸ–¼  Topâ€‘4 ì œí’ˆ ì´ë¯¸ì§€ URL")
            for pid in pids:
                image_url = get_best_image_url(images_by_pid.get(pid, []))
                if image_url:
                    print(f"{pid}: {image_url}")
            
            # ì‚¬ìš©ìì—ê²Œ ë¹„ë””ì˜¤ ë³€í™˜ ì—¬ë¶€ ë¬»ê¸°
            should_convert = input("\nì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            
            if should_convert == 'y':
                model_type = input("ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš” (svd/svd_xt, ê¸°ë³¸ê°’: svd): ").strip().lower()
                if model_type not in MODEL_NAMES:
                    model_type = "svd"
                    
                print(f"\n[i] ëª¨ë¸ ì •ë³´: {MODEL_NAMES[model_type]}")
                print(f"[i] ì˜ˆìƒ ë¹„ìš©: ${MODEL_PRICING[model_type]}/ë¹„ë””ì˜¤")
                
                if not NOVITA_API_KEY:
                    print("[!] NOVITA_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
                else:
                    # ì‚¬ìš©ìê°€ ë³€í™˜í•  ì œí’ˆ ì„ íƒ
                    print("\në³€í™˜í•  ì œí’ˆì˜ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì—¬ëŸ¬ ì œí’ˆ ì„ íƒ ê°€ëŠ¥, ì˜ˆ: 1,3):")
                    for i, pid in enumerate(pids, 1):
                        print(f"{i}. {pid}")
                    
                    selection = input("ì„ íƒ: ").strip()
                    selected_indices = []
                    
                    try:
                        # ì„ íƒí•œ ë²ˆí˜¸ë¥¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
                        if selection == "all":
                            selected_indices = list(range(len(pids)))
                        else:
                            selected_indices = [int(idx.strip())-1 for idx in selection.split(",")]
                        
                        # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ í•„í„°ë§
                        selected_indices = [idx for idx in selected_indices if 0 <= idx < len(pids)]
                        
                        if selected_indices:
                            results = []
                            
                            for idx in selected_indices:
                                pid = pids[idx]
                                image_url = get_best_image_url(images_by_pid.get(pid, []))
                                
                                if image_url:
                                    print(f"\n[+] ì œí’ˆ {pid} ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜ ì¤‘...")
                                    result = process_product_to_video(pid, image_url, model=model_type)
                                    results.append((pid, result))
                                else:
                                    print(f"[!] ì œí’ˆ {pid}ì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # ê²°ê³¼ ìš”ì•½
                            print("\n=== ë³€í™˜ ê²°ê³¼ ìš”ì•½ ===")
                            success_count = sum(1 for _, r in results if r.get("success"))
                            print(f"ì„±ê³µ: {success_count}/{len(results)}")
                            
                            for pid, result in results:
                                if result.get("success"):
                                    status = "ê¸°ì¡´ ë¹„ë””ì˜¤ ì‚¬ìš©" if result.get("already_exists") else "ìƒˆë¡œ ìƒì„±ë¨"
                                    video_path = result.get("video_path", "")
                                    print(f"[âœ“] ì œí’ˆ {pid} ë¹„ë””ì˜¤ {status}: {video_path}")
                                else:
                                    error = result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                                    print(f"[âœ—] ì œí’ˆ {pid} ë¹„ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {error}")
                            
                            # ë¹„ìš© ê³„ì‚°
                            new_videos = sum(1 for _, r in results if r.get("success") and not r.get("already_exists"))
                            if new_videos > 0:
                                total_cost = MODEL_PRICING.get(model_type, 0) * new_videos
                                print(f"\n[i] ì´ ë¹„ìš©: ${total_cost:.4f} ({new_videos}ê°œ ë¹„ë””ì˜¤ ìƒì„±)")
                                
                    except ValueError:
                        print("[!] ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")

            return

        # User prompt â†” answer ìˆ˜ì§‘
        print(f"Agent: {question}")
        answer = input("You: ").strip()

        qa_turns.append((question, answer))
        # Generation: ëŒ€í™” ì´ë ¥ ê¸°ë°˜ ì¿¼ë¦¬ ì¬êµ¬ì„±
        search_query = reformulate_query(llm, qa_turns)
        print(f"[ refinedâ€‘query ] â†’ {search_query}\n")


def fetch_images_for_pids(pids: list[str]) -> dict[str, list[str]]:
    """
    Return {pid: [image_url, â€¦]} for every pid in `pids`
    by looking them up in the Amazonâ€‘Reviewsâ€‘2023 metadata split.
    """
    pid_set = set(pids)

    meta_ds = load_dataset(
        "McAuley-Lab/Amazon-Reviews-2023",
        "raw_meta_Toys_and_Games",   # â† category split that matches your index
        split="full",
        trust_remote_code=True,
    )

    # HuggingFace Datasets supports vectorised filtering, which is faster
    sub_ds = meta_ds.filter(lambda r: r["parent_asin"] in pid_set)

    # zip â†’ dict: parent_asin â” images (list of URLs)
    return dict(zip(sub_ds["parent_asin"], sub_ds["images"]))


def encode_image_to_base64(image_path):
    """ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode("utf-8")
    except Exception as e:
        print(f"[!] ì´ë¯¸ì§€ ì¸ì½”ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""


def resize_image(image_path, output_path=None):
    """ì´ë¯¸ì§€ í¬ê¸°ë¥¼ API ì œí•œì— ë§ê²Œ ì¡°ì •í•©ë‹ˆë‹¤."""
    if output_path is None:
        output_path = image_path
        
    try:
        img = Image.open(image_path)
        width, height = img.size
        
        if width > MAX_IMAGE_WIDTH or height > MAX_IMAGE_HEIGHT:
            if width / MAX_IMAGE_WIDTH > height / MAX_IMAGE_HEIGHT:
                new_width = MAX_IMAGE_WIDTH
                new_height = int(height * (MAX_IMAGE_WIDTH / width))
            else:
                new_height = MAX_IMAGE_HEIGHT
                new_width = int(width * (MAX_IMAGE_HEIGHT / height))
            
            resized_img = img.resize((new_width, new_height), Image.LANCZOS)
            print(f"[+] ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {width}x{height} â†’ {new_width}x{new_height}")
            resized_img.save(output_path)
            return True
        else:
            print(f"[+] ì´ë¯¸ì§€ í¬ê¸° ì í•©: {width}x{height}, ì¡°ì • ë¶ˆí•„ìš”")
            return True
    except Exception as e:
        print(f"[!] ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨: {e}")
        return False


def download_image(url, save_path):
    """URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        response = requests.get(url, stream=True)
        if response.status_code == 200:
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(1024):
                    f.write(chunk)
            return True
        else:
            print(f"[!] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
            return False
    except Exception as e:
        print(f"[!] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def get_best_image_url(images):
    """ì´ë¯¸ì§€ ëª©ë¡ì—ì„œ ê°€ì¥ ì¢‹ì€ í’ˆì§ˆì˜ ì´ë¯¸ì§€ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not images or not isinstance(images, list):
        return None
    
    for img in images:
        if isinstance(img, dict):
            if img.get("hi_res"):
                return img["hi_res"]
            elif img.get("large"):
                return img["large"]
            elif img.get("thumb"):
                return img["thumb"]
    
    return None


def convert_image_to_video(image_path, output_path, model="svd"):
    """Novita APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not NOVITA_API_KEY:
        print("[!] NOVITA_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        return {"success": False, "error": "API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤"}
    
    try:
        # ëª¨ë¸ ì„ íƒ ë° ì˜ˆìƒ ë¹„ìš© ê³„ì‚°
        model_name = MODEL_NAMES.get(model.lower())
        estimated_cost = MODEL_PRICING.get(model.lower(), "ì•Œ ìˆ˜ ì—†ìŒ")
        print(f"[i] ì„ íƒí•œ ëª¨ë¸: {model_name}, ì˜ˆìƒ ë¹„ìš©: ${estimated_cost}/ë¹„ë””ì˜¤")
        
        # ì´ë¯¸ì§€ base64ë¡œ ì¸ì½”ë”©
        image_base64 = encode_image_to_base64(image_path)
        if not image_base64:
            return {"success": False, "error": "ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨"}
        
        # API íŒŒë¼ë¯¸í„° ì„¤ì •
        frames_num = 14 if model.lower() == "svd" else 25
        
        payload = {
            "model_name": model_name,
            "image_file": image_base64,
            "frames_num": frames_num,
            "frames_per_second": 6,
            "image_file_resize_mode": "ORIGINAL_RESOLUTION",
            "steps": 20,
            "motion_bucket_id": 40,
            "cond_aug": 0.02
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {NOVITA_API_KEY}"
        }
        
        print(f"[+] Novita API í˜¸ì¶œ ì‹œì‘: ì´ë¯¸ì§€ {image_path} â†’ ë¹„ë””ì˜¤ ë³€í™˜ ì¤‘...")
        
        # API í˜¸ì¶œ
        response = requests.post(NOVITA_API_URL, json=payload, headers=headers)
        print(f"[+] API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            task_id = result.get("task_id")
            
            if not task_id:
                return {"success": False, "error": "ì‘ì—… IDë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"}
            
            print(f"[+] ì‘ì—… ID: {task_id}. ë³€í™˜ ì‹œì‘...")
            return check_video_conversion_status(task_id, output_path, model=model)
        else:
            print(f"[!] API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
            return {"success": False, "error": f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}"}
    except Exception as e:
        print(f"[!] ë¹„ë””ì˜¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"success": False, "error": str(e)}


def check_video_conversion_status(task_id, output_path, model="svd"):
    """ë¹„ë””ì˜¤ ë³€í™˜ ì‘ì—… ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì™„ë£Œë˜ë©´ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    status_url = f"https://api.novita.ai/v3/async/task-result?task_id={task_id}"
    
    headers = {
        "Authorization": f"Bearer {NOVITA_API_KEY}"
    }
    
    max_attempts = 10
    for attempt in range(max_attempts):
        try:
            response = requests.get(status_url, headers=headers)
            
            if response.status_code == 200:
                result = response.json()
                task_info = result.get("task", {})
                status = task_info.get("status")
                
                if status == "TASK_STATUS_SUCCEED":
                    videos = result.get("videos", [])
                    if videos and len(videos) > 0:
                        video_url = videos[0].get("video_url")
                        if video_url:
                            print(f"[+] ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ. ë‹¤ìš´ë¡œë“œ ì¤‘...")
                            video_response = requests.get(video_url)
                            if video_response.status_code == 200:
                                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                                with open(output_path, 'wb') as f:
                                    f.write(video_response.content)
                                print(f"[âœ“] ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path}")
                                return {"success": True, "video_path": output_path}
                            else:
                                return {"success": False, "error": "ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"}
                        else:
                            return {"success": False, "error": "ë¹„ë””ì˜¤ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
                    else:
                        return {"success": False, "error": "ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
                elif status == "TASK_STATUS_FAILED":
                    reason = task_info.get("reason", "ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ ")
                    return {"success": False, "error": f"ì‘ì—… ì‹¤íŒ¨: {reason}"}
                elif status == "TASK_STATUS_PENDING" or status == "TASK_STATUS_RUNNING":
                    progress = task_info.get("progress_percent", 0)
                    print(f"[+] ë³€í™˜ ì¤‘... ({attempt+1}/{max_attempts}) - ì§„í–‰ë¥ : {progress}%")
                    time.sleep(10)
                else:
                    time.sleep(10)
            else:
                time.sleep(10)
        except Exception as e:
            print(f"[!] ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            time.sleep(10)
    
    return {"success": False, "error": "ì‹œê°„ ì´ˆê³¼"}


def process_product_to_video(product_id, image_url, output_dir="output_videos", model="svd"):
    """ì œí’ˆ ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""    
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    temp_dir = os.path.join(output_dir, "temp")
    os.makedirs(temp_dir, exist_ok=True)
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    image_path = os.path.join(temp_dir, f"{product_id}.jpg")
    video_path = os.path.join(output_dir, f"{product_id}.mp4")
    
    # ì´ë¯¸ì§€ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(image_path):
        if not download_image(image_url, image_path):
            return {"success": False, "error": "ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"}
    
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    if not resize_image(image_path):
        return {"success": False, "error": "ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ì‹¤íŒ¨"}
    
    # ë¹„ë””ì˜¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if os.path.exists(video_path):
        print(f"[!] ë¹„ë””ì˜¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {video_path}")
        return {"success": True, "video_path": video_path, "already_exists": True}
    
    # ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜
    result = convert_image_to_video(image_path, video_path, model=model)
    
    if result.get("success"):
        result["model"] = model
    
    return result


if __name__ == "__main__":
    try:
        conversational_search()
    except KeyboardInterrupt:
        print("\n[Session terminated]")
